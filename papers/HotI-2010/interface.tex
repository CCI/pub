\section{The CCI Interface}

\subsection{Endpoints}
An endpoint is a virtualized instance of a device, it is the logical source 
or destination of all communications in CCI. An endpoint contains both a send 
and receive queue and their associated buffers, it is a complete container 
of all resources used by an application process or thread to perform CCI 
operations. As such, endpoints naturally fit the NUMA architecture, they can 
be bound to particular cores to maximize locality.

Endpoints interact with the application through events. CCI provides a 
function to immediately return the next event for a particular endpoint. 
Optionally, this function can block if no events are available, allowing the 
application thread to be scheduled out by the operating system. To facilitate 
the integration of the blocking semantic with non-CCI operations, each endpoint 
exposes an OS-specific handle such as file descriptor in Linux or an object in 
Windows.

The concept of endpoint is key to scalability. By multiplexing incoming 
messages into a shared receive queue and similarly buffering outgoing 
messages in a shared send queue, the overall memory footprint is independent 
of the number of peers communicating with the endpoint. On the time dimension, 
an endpoint offers a unified completion queue, allowing for OS-bypass 
implementations to provide low latency at scale.

\subsection{Connections}
CCI uses connections to represent the state of communication channels with 
remote peers. An endpoint can be connected to another endpoint through one or 
more connections. Connections have different attributes, such as 
reliability and order. CCI supports five different connection types:

\begin{itemize}
\item Reliable with Ordered completion (RO)
\item Reliable with Unordered completion (RU)
\item Unreliable with Unordered completion (UU)
\item Multicast Send (MC\_TX)
\item Multicast Receive (MC\_RX)
\end{itemize}

As previously stated, unreliable connections are useful for 



CCI defines a \emph{connection} struct which includes the maximum send size negotiated by
the two instances of CCI, a pointer to the owning endpoint, and the connection attribute.

As mentioned above, some applications may need reliable delivery while other may not.
Among applications needing reliable delivery, some may need in-order completion (e.g.
traditional SOCK\_STREAM semantics) and others may accept out-of-order completion as long
as communications are initiated in-order (e.g. MPI point-to-point).



It is also an opportunity to allow the client to pass credentials to the
server if authentication and/or authorization is required and it is an opportunity for the
two sides to negotiate message sizes, the number of messages in flight, and other internal
information as appropriate.

\subsection{Connection Establishment}
As we previously discussed, part of the robustness of the sockets API is its client/server
connection semantics. CCI mirrors those semantics. A process willing to accept connections
will first \f{bind} a device to a name service at a specified \emph{port} and a
\emph{backlog} parameter. The call returns a pointer to a \emph{service}. When a server no
longer wishes to receive connection requests, it can \f{unbind} from the service.

To initiate a connection, the client calls \f{connect} with parameters including an
endpoint, a string URI for the server, the port, optionally a pointer to a limited sized
payload and its length, the connection attribute, a pointer to an optional application
context, and a timeout.

The server then polls for connection requests using \f{get\_conn\_request} passing in the
service pointer. If one is ready, it returns a \emph{conn\_req} struct which contains an
array of compatible devices, the number of devices in the array, a pointer to the
application payload and its length if the client sent it, and the requested connection
attribute.

The server then calls either \f{accept} or \f{reject}. The \f{accept} call binds the
connection request to an endpoint previously created from one of the compatible devices
and returns a connection pointer. The client gets an OTHER event with the type
CONNECT\_SUCCESS. If the server calls \f{reject}, the client get an other event with the
type CONNECT\_REJECTED.  On the server, the connection request is stale after either call.
If the server does not reply within the timeout set in the client's \f{connect}, the
client gets an OTHER event with a type of CONNECT\_TIMEOUT. When a process no longer needs
a connection, it can call \f{disconnect}.

\subsection{Active Messages}

\note{Below is mostly Patrick's text from his outline}
Buffered messages as in sockets provide asynchronism but consume time and 
space. Asynchronism is fundamental for scalability, but space is bounded and 
time is precious. 
Matching interfaces (as used in MPI) are powerful but very complex. The 
matching semantics (wildcards) may require coherent matching implementation, 
preventing effective offload (has to be done in the host). Furthermore, 
matching generally requires support for unexpected messages, which consumes 
time and space. Finally matching interfaces are stateful, which is bad for 
fault-tolerance and offload.  Socket's SOCK\_STREAM semantic is akin to 
ordered matching, all messages demultiplexed to the same destination socket 
are treated as unexpected messages until consumed.

Active Messages is well known solution but has two problems: async handlers 
and reassembly of large messages.  Async handlers are unbounded in term of 
running time. CCI uses events instead.  Messages larger than MTU requires 
reassembly: means stateful (bad), means unexpected buffers (bad). The solution 
is to limit message size to MTU, segmentation/reassembly in application.

Once the connection is established, the two processes can start communicating. CCI
provides two methods, active messages and remote memory access (RMA), which we discuss in
the next section.

CCI's version of active messages does not fully mirror Active Messages\cite{voneicken-isca92} (AM). Like
the original AM, CCI's active messages have a maximum size that is device dependent.
Ideally, the size is equal to the link MTU (less wire headers). The driving idea to
limiting the message size to a single MTU is that future networks may have many paths
through the network due to fabrics with high-radix switches and/or NICs with multiple
ports connected to redundant switches for fault-tolerance.  Limiting the active message
size limited to a single MTU vastly simplifies the requirements for message completion ---
either it arrives or it does not.

Where CCI differs from the original Active Messages is handling of incoming messages.  In
Active Messages, the message contains an address of the handler that will process it,
which assumes all processes have identical memory spaces.  The difficulty with invoking
handlers is there is no bound on how long the handler will run.  While running, the
communication library cannot process any more messages and could lead to dropping
messages. Instead, CCI returns an event of type RECV. The application can get the event
and hold it without blocking CCI from continuing to service other communications.

The \f{send} parameters include the connection, header and data pointers and their
respective lengths, an application context pointer, and flags. Either or both of the
pointers may be NULL. The header is currently limited to a maximum length of 32 bytes. The
context pointer is returned in the SEND completion event and can be used to allow the
application to retrieve its internal state.


\subsection{Remote Memory Access}
Clearly, messages limited to a single MTU will not meet the needs of all applications.
Applications such as file systems which need to move large, bulk messages need much more.
To accommodate them, CCI also provides remote memory access (RMA). RMA transfers are only
allowed on reliable connections.

Before using RMA, the process needs to explicitly register the memory. CCI provides
\f{rma\_register} which takes pointers to the endpoint, the connection, and the start of
the region to be registered as well as the length of the region and it returns a RMA
handle. If the connection pointer is set, RMA operations on that handle will be limited to
that one connection. If the connection is NULL, then RMA operations on that handle will be
limited to any connection on that endpoint.  When a process no longer needs to RMA in to
or out of the region, it passes the handle to \f{rma\_deregister}.

For a RMA transfer to take place, both processes must register their local memory and they
need to pass the handle of the target process to the initiator process using one or more
active messages. The full \f{rma} signature is:

\begin{verbatim}
int rma(cci_connection_t *connection,
        void *header_ptr,
        uint32_t header_len,
        uint64_t local_handle,
        uint64_t local_offset,
        uint64_t remote_handle,
        uint64_t remote_offset,
        uint64_t data_len,
        void *context,
        int flags);
\end{verbatim}

The call takes the connection pointer, an optional header pointer and length, the local
RMA handle and offset, the remote RMA handle and offset, the transfer length, an
application context pointer, and a set of flags.

If the header pointer and length are set, the initiator will send a completion message to
the target that arrives as an active message with the header set and no data payload. Like
with \f{send}, the header length is limited to 32 bytes.

The flag options include:

\begin{description}
\item BLOCKING (see \f{send})
\item SILENT (see \f{send})
\item READ allows data to move from remote to local memory.
\item WRITE allows data to move from local to remote memory.
\item FENCE means wait for all previous RMA operations to complete before performing this
operation and all following RMA operations.
\end{description}

CCI does not guarantee delivery order within an operation (i.e. no last-byte-written-last
mandate), but order is guaranteed between data delivery and the remote receive event if
the header is specified.

\note{thoughts?} Explicit memory registration which is missing from MPI.\note{why is this
good, George?} Simpler semantics and coding compared to Verbs.\note{is this true, Dave?}
